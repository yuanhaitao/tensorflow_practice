{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "def vectorize_dic(dic,ix=None,p=None,n=0,g=0):\n",
    "    \"\"\"\n",
    "    dic -- dictionary of feature lists. Keys are the name of features\n",
    "    ix -- index generator (default None)\n",
    "    p -- dimension of featrure space (number of columns in the sparse matrix) (default None)\n",
    "    \"\"\"\n",
    "    if ix==None:\n",
    "        ix = dict()\n",
    "\n",
    "    nz = n * g\n",
    "\n",
    "    col_ix = np.empty(nz,dtype = int)\n",
    "\n",
    "    i = 0\n",
    "    for k,lis in dic.items():\n",
    "        for t in range(len(lis)):\n",
    "            ix[str(lis[t]) + str(k)] = ix.get(str(lis[t]) + str(k),0) + 1\n",
    "            col_ix[i+t*g] = ix[str(lis[t]) + str(k)]\n",
    "        i += 1\n",
    "\n",
    "    row_ix = np.repeat(np.arange(0,n),g)\n",
    "    data = np.ones(nz)\n",
    "    if p == None:\n",
    "        p = len(ix)\n",
    "\n",
    "    ixx = np.where(col_ix < p)\n",
    "    return csr.csr_matrix((data[ixx],(row_ix[ixx],col_ix[ixx])),shape=(n,p)),ix\n",
    "\n",
    "\n",
    "def batcher(X_, y_=None, batch_size=-1):\n",
    "    n_samples = X_.shape[0]\n",
    "\n",
    "    if batch_size == -1:\n",
    "        batch_size = n_samples\n",
    "    if batch_size < 1:\n",
    "       raise ValueError('Parameter batch_size={} is unsupported'.format(batch_size))\n",
    "\n",
    "    for i in range(0, n_samples, batch_size):\n",
    "        upper_bound = min(i + batch_size, n_samples)\n",
    "        ret_x = X_[i:upper_bound]\n",
    "        ret_y = None\n",
    "        if y_ is not None:\n",
    "            ret_y = y_[i:i + batch_size]\n",
    "            yield (ret_x, ret_y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['user','item','rating','timestamp']\n",
    "\n",
    "train = pd.read_csv('/Users/macbookpro/Documents/Lab_Git/tensorflow_practice/recommendation/recommendation-FM-demo/data/ua.base',delimiter='\\t',names = cols)\n",
    "test = pd.read_csv('/Users/macbookpro/Documents/Lab_Git/tensorflow_practice/recommendation/recommendation-FM-demo/data/ua.test',delimiter='\\t',names = cols)\n",
    "\n",
    "x_train,ix = vectorize_dic({'users':train['user'].values,\n",
    "                            'items':train['item'].values},n=len(train.index),g=2)\n",
    "x_test,ix = vectorize_dic({'users':test['user'].values,\n",
    "                           'items':test['item'].values},ix,x_train.shape[1],n=len(test.index),g=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t2.0\n",
      "  (1, 1)\t1.0\n",
      "  (1, 2)\t1.0\n",
      "  (2, 1)\t1.0\n",
      "  (2, 3)\t1.0\n",
      "  (3, 1)\t1.0\n",
      "  (3, 4)\t1.0\n",
      "  (4, 1)\t1.0\n",
      "  (4, 5)\t1.0\n",
      "  (5, 1)\t1.0\n",
      "  (5, 6)\t1.0\n",
      "  (6, 1)\t1.0\n",
      "  (6, 7)\t1.0\n",
      "  (7, 1)\t1.0\n",
      "  (7, 8)\t1.0\n",
      "  (8, 1)\t1.0\n",
      "  (8, 9)\t1.0\n",
      "  (9, 1)\t1.0\n",
      "  (9, 10)\t1.0\n",
      "  (10, 1)\t1.0\n",
      "  (10, 11)\t1.0\n",
      "  (11, 1)\t1.0\n",
      "  (11, 12)\t1.0\n",
      "  (12, 1)\t1.0\n",
      "  (12, 13)\t1.0\n",
      "  :\t:\n",
      "  (90557, 146)\t1.0\n",
      "  (90558, 51)\t1.0\n",
      "  (90558, 147)\t1.0\n",
      "  (90559, 96)\t1.0\n",
      "  (90559, 148)\t1.0\n",
      "  (90560, 44)\t1.0\n",
      "  (90560, 149)\t1.0\n",
      "  (90561, 38)\t1.0\n",
      "  (90561, 150)\t1.0\n",
      "  (90562, 90)\t1.0\n",
      "  (90562, 151)\t1.0\n",
      "  (90563, 133)\t1.0\n",
      "  (90563, 152)\t1.0\n",
      "  (90564, 38)\t1.0\n",
      "  (90564, 153)\t1.0\n",
      "  (90565, 115)\t1.0\n",
      "  (90565, 154)\t1.0\n",
      "  (90566, 71)\t1.0\n",
      "  (90566, 155)\t1.0\n",
      "  (90567, 41)\t1.0\n",
      "  (90567, 156)\t1.0\n",
      "  (90568, 46)\t1.0\n",
      "  (90568, 157)\t1.0\n",
      "  (90569, 4)\t1.0\n",
      "  (90569, 158)\t1.0\n",
      "[[ 0.  2.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  1. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "(90570, 2623)\n",
      "(9430, 2623)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd84e1b2cbf494a97288a64c251cb10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.6236\n",
      "13.1047\n",
      "12.5847\n",
      "12.736\n",
      "11.4308\n",
      "11.5647\n",
      "10.8447\n",
      "10.632\n",
      "10.3845\n",
      "9.20325\n",
      "9.64259\n",
      "9.16006\n",
      "8.76089\n",
      "8.61368\n",
      "7.97011\n",
      "8.15394\n",
      "7.47999\n",
      "7.48789\n",
      "7.16596\n",
      "6.97665\n",
      "6.54898\n",
      "6.16551\n",
      "6.38799\n",
      "5.68104\n",
      "5.99215\n",
      "5.6804\n",
      "5.46853\n",
      "5.46394\n",
      "5.24609\n",
      "5.07216\n",
      "5.00078\n",
      "4.697\n",
      "4.68722\n",
      "4.57986\n",
      "4.21117\n",
      "4.15247\n",
      "4.21973\n",
      "4.01742\n",
      "3.92202\n",
      "3.78237\n",
      "3.56096\n",
      "3.53148\n",
      "3.32603\n",
      "3.15472\n",
      "3.35881\n",
      "3.21887\n",
      "3.17315\n",
      "2.98264\n",
      "2.97366\n",
      "2.7619\n",
      "2.91412\n",
      "2.75449\n",
      "2.72759\n",
      "2.61522\n",
      "2.50575\n",
      "2.6606\n",
      "2.42602\n",
      "2.54056\n",
      "2.40632\n",
      "2.33074\n",
      "2.34409\n",
      "2.2501\n",
      "2.2062\n",
      "2.30523\n",
      "2.22355\n",
      "2.10251\n",
      "1.98715\n",
      "2.02659\n",
      "2.01722\n",
      "1.95219\n",
      "1.99849\n",
      "1.9881\n",
      "2.05364\n",
      "1.99524\n",
      "1.84384\n",
      "1.72929\n",
      "1.7336\n",
      "1.78619\n",
      "1.84003\n",
      "1.74338\n",
      "1.77738\n",
      "1.75516\n",
      "1.6484\n",
      "1.71948\n",
      "1.8096\n",
      "1.58555\n",
      "1.71198\n",
      "1.60611\n",
      "1.58027\n",
      "1.64584\n",
      "1.64798\n",
      "1.52954\n",
      "1.59635\n",
      "1.63917\n",
      "1.50611\n",
      "1.47844\n",
      "1.52141\n",
      "1.57433\n",
      "1.46684\n",
      "1.38352\n",
      "1.39818\n",
      "1.40208\n",
      "1.48979\n",
      "1.448\n",
      "1.44868\n",
      "1.54828\n",
      "1.49759\n",
      "1.45274\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(x_train)\n",
    "y_train = train['rating'].values\n",
    "y_test = test['rating'].values\n",
    "\n",
    "x_train = x_train.todense()\n",
    "x_test = x_test.todense()\n",
    "\n",
    "print(x_train)\n",
    "\n",
    "print(x_train.shape)\n",
    "print (x_test.shape)\n",
    "\n",
    "\n",
    "n,p = x_train.shape\n",
    "\n",
    "k = 10\n",
    "\n",
    "x = tf.placeholder('float',[None,p])\n",
    "\n",
    "y = tf.placeholder('float',[None,1])\n",
    "\n",
    "w0 = tf.Variable(tf.zeros([1]))\n",
    "w = tf.Variable(tf.zeros([p]))\n",
    "\n",
    "v = tf.Variable(tf.random_normal([k,p],mean=0,stddev=0.01))\n",
    "\n",
    "#y_hat = tf.Variable(tf.zeros([n,1]))\n",
    "\n",
    "linear_terms = tf.add(w0,tf.reduce_sum(tf.multiply(w,x),1,keep_dims=True)) # n * 1\n",
    "pair_interactions = 0.5 * tf.reduce_sum(\n",
    "    tf.subtract(\n",
    "        tf.pow(\n",
    "            tf.matmul(x,tf.transpose(v)),2),\n",
    "        tf.matmul(tf.pow(x,2),tf.transpose(tf.pow(v,2)))\n",
    "    ),axis = 1 , keep_dims=True)\n",
    "\n",
    "\n",
    "y_hat = tf.add(linear_terms,pair_interactions)\n",
    "\n",
    "lambda_w = tf.constant(0.001,name='lambda_w')\n",
    "lambda_v = tf.constant(0.001,name='lambda_v')\n",
    "\n",
    "l2_norm = tf.reduce_sum(\n",
    "    tf.add(\n",
    "        tf.multiply(lambda_w,tf.pow(w,2)),\n",
    "        tf.multiply(lambda_v,tf.pow(v,2))\n",
    "    )\n",
    ")\n",
    "\n",
    "error = tf.reduce_mean(tf.square(y-y_hat))\n",
    "loss = tf.add(error,l2_norm)\n",
    "\n",
    "\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(loss)\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 1000\n",
    "\n",
    "# Launch the graph\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in tqdm(range(epochs), unit='epoch'):\n",
    "        perm = np.random.permutation(x_train.shape[0])\n",
    "        # iterate over batches\n",
    "        for bX, bY in batcher(x_train[perm], y_train[perm], batch_size):\n",
    "            _,t = sess.run([train_op,loss], feed_dict={x: bX.reshape(-1, p), y: bY.reshape(-1, 1)})\n",
    "            print(t)\n",
    "\n",
    "\n",
    "    errors = []\n",
    "    for bX, bY in batcher(x_test, y_test):\n",
    "        errors.append(sess.run(error, feed_dict={x: bX.reshape(-1, p), y: bY.reshape(-1, 1)}))\n",
    "        print(errors)\n",
    "    RMSE = np.sqrt(np.array(errors).mean())\n",
    "    print (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
